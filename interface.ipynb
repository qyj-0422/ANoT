{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------#\n",
    "###构建模型###\n",
    "#--------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters\n",
    "graph_name = 'GDELT'\n",
    "root_path = '/home/zhangjs/expriment/TKGist/data/'\n",
    "dataset = graph_name+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1734399it [08:15, 3503.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 7146\n",
      "|E| = 1734399\n",
      "|L_V| = 127\n",
      "|L_E| = 238\n",
      "|Rule| = 22164\n"
     ]
    }
   ],
   "source": [
    "# load graph\n",
    "\n",
    "import pickle\n",
    "from graph import Graph\n",
    "graph = Graph(graph_name, idify=False)\n",
    "pickle.dump(graph, open(root_path + dataset + \"graph_new.pickle\", \"wb\"))\n",
    "# 4m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking rules....\n",
      "constructing raw model...\n",
      "Null encoding cost: 12165840.136\n",
      "Starting pass 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22164it [00:16, 1325.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rules after pass 2: 432\n",
      "Starting pass 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22164it [00:11, 1858.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rules after pass 3: 434\n",
      "Starting pass 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22164it [00:11, 1958.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rules after pass 4: 434\n",
      "----- Model stats -----\n",
      "L(G,M) = 615613.84\n",
      "% Bits needed: 5.06\n",
      "# Rules: 434\n",
      "% Edges Explained: 99.58\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# create a Searcher object to search for a model (set of rules) and build the raw model\n",
    "from searcher import Searcher\n",
    "searcher = Searcher(graph)\n",
    "model = searcher.build_model()\n",
    "pickle.dump(model, open(root_path + dataset + \"static_model_new.pickle\", \"wb\"))\n",
    "model.print_stats()\n",
    "#1m40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating chain combinations....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371010/371010 [02:15<00:00, 2738.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get candidate rule pairs: 796030\n",
      "generating riangle combinations....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 55/2138 [33:15<20:59:33, 36.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get candidate rule riangle: 10047127\n",
      "Null encoding cost: 145739678.0579\n",
      "Starting pass 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7796030it [03:18, 39248.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of combined_rules after pass 2: 27847\n",
      "----- Model stats -----\n",
      "L(G,M) = 87782464.46\n",
      "[87782464.46079448, 145739678.05791223]\n",
      "% Bits needed: 60.23\n",
      "# Rules: 27847\n",
      "% Edges Explained: 89.49\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# build the temporal model\n",
    "temporal_model, candidate_p, candidate_t = searcher.build_temporal_model(model)\n",
    "pickle.dump(temporal_model, open(root_path + dataset + \"temporal_model_new.pickle\", \"wb\"))\n",
    "temporal_model.print_stats(temporal_model)\n",
    "#10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "----- Model stats -----\n",
    "L(G,M) = 47874454.58\n",
    "[47874454.580734275, 71251217.27922314]\n",
    "% Bits needed: 67.19\n",
    "# Rules: 11385\n",
    "% Edges Explained: 87.49\n",
    "-----------------------\n",
    "generating chain combinations....\n",
    "100%|██████████| 40839/40839 [01:11<00:00, 567.66it/s] \n",
    "get candidate rule pairs: 1041156\n",
    "generating riangle combinations....\n",
    "100%|██████████| 304/304 [10:29<00:00,  2.07s/it]\n",
    "get candidate rule riangle: 7807869\n",
    "Null encoding cost: 17824148.4108\n",
    "Starting pass 1.\n",
    "1041156it [00:33, 31032.89it/s]\n",
    "Final number of combined_rules after pass 2: 4576\n",
    "Null encoding cost: 17824148.4108\n",
    "Starting pass 1.\n",
    "7807869it [03:31, 36886.14it/s]\n",
    "Final number of combined_rules after pass 2: 2582\n",
    "----- Model stats -----\n",
    "L(G,M) = 14832424.81\n",
    "[14832424.807377124, 17824148.41079742]\n",
    "% Bits needed: 83.22\n",
    "# Rules: 7158\n",
    "% Edges Explained: 80.86\n",
    "-----------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### directly read preserved files\n",
    "\n",
    "import pickle\n",
    "graph_name = 'YAGO'\n",
    "root_path = '/home/zhangjs/expriment/TKGist/data/'\n",
    "dataset = graph_name+'/'\n",
    "\n",
    "graph = pickle.load(open(root_path + dataset + \"graph_new.pickle\", \"rb\"))\n",
    "model = pickle.load(open(root_path + dataset + \"static_model_new.pickle\", \"rb\"))\n",
    "temporal_model = pickle.load(open(root_path + dataset + \"temporal_model_new.pickle\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlize the detection function\n",
    "import pickle\n",
    "from anomaly_detector import AnomalyDetector\n",
    "from model_updater import ModelUpdater\n",
    "\n",
    "detector = AnomalyDetector(temporal_model)\n",
    "\n",
    "def read_file(input_file):\n",
    "    raw_data = []\n",
    "    for fact in input_file.readlines():\n",
    "        s, r, o, t = fact.strip().split('\t')[:4]\n",
    "        s = int(s)\n",
    "        r = int(r)\n",
    "        o = int(o)\n",
    "        t = int(t)\n",
    "        raw_data.append((s, r, o, t))\n",
    "    return raw_data\n",
    "\n",
    "valid_pos, test_pos = read_file(open(root_path + dataset + 'valid.txt', 'r')), read_file(open(root_path + dataset + 'test.txt', 'r'))\n",
    "valid_t_2_C_neg, test_t_2_C_neg = pickle.load(open(root_path + dataset + '/conceptual_errors.pickle', 'rb'))\n",
    "valid_t_2_T_neg, test_t_2_T_neg = pickle.load(open(root_path + dataset + '/time_errors.pickle', 'rb'))\n",
    "valid_t_2_M_neg, test_t_2_M_neg = pickle.load(open(root_path + dataset + '/missing_errors.pickle', 'rb'))\n",
    "\n",
    "valid_t_2_pos = {}\n",
    "test_t_2_pos = {}\n",
    "for sample in valid_pos:\n",
    "    s, r, o, t = sample\n",
    "    if t not in valid_t_2_pos.keys():\n",
    "        valid_t_2_pos[t] = []\n",
    "    valid_t_2_pos[t].append((int(s), int(r), int(o), int(t)))\n",
    "\n",
    "\n",
    "for sample in test_pos:\n",
    "    s, r, o, t = sample\n",
    "    if t not in test_t_2_pos.keys():\n",
    "        test_t_2_pos[t] = []\n",
    "    test_t_2_pos[t].append((int(s), int(r), int(o), int(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:00<00:00, 57325.83it/s]\n",
      "100%|██████████| 10/10 [25:38<00:00, 153.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Result stats -----concept\n",
      "Number of test samples: 9161\n",
      "Number of anomaly samples: 2110\n",
      "-----------------------\n",
      "Best result by F1-score:\n",
      "P: 0.4179757407039173\n",
      "F05: 0.4728696121659318\n",
      "AUC: 0.7913078444723313\n",
      "----- Result stats -----time\n",
      "Number of test samples: 9161\n",
      "Number of anomaly samples: 2110\n",
      "-----------------------\n",
      "Best result by F1-score:\n",
      "P: 0.23057589334498962\n",
      "F05: 0.2725112362452859\n",
      "AUC: 0.47730058793045393\n",
      "----- Result stats -----missing\n",
      "Number of test samples: 6330\n",
      "Number of anomaly samples: 2110\n",
      "-----------------------\n",
      "Best result by F1-score:\n",
      "P: 0.3685467024768726\n",
      "F05: 0.3980275879850458\n",
      "AUC: 0.5371391590485389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# detect concept+time+missing anomaly\n",
    "# next_step_rules_list = list(next_step_rules)\n",
    "# for rule_pair in next_step_rules_list[:max_rule]:\n",
    "# #for rule_pair in rules.keys():\n",
    "        #    self.updater.update_temporal_model(self.temporal_model, rule_pair[0], rule_pair[1], rules[rule_pair], sample_size)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.dummy import freeze_support, Manager\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, f1_score\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def get_f1(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2*(p*r)/(p+r)\n",
    "\n",
    "def get_f05(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.25*(p*r)/(0.25*p+r)\n",
    "        \n",
    "def get_metric(pred, y, anomaly_type):\n",
    "    precision, recall, threshold = precision_recall_curve(y, pred)\n",
    "    # find the best threshold by F1 score\n",
    "\n",
    "    f1s = [get_f1(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    f05s = [get_f05(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    optimal_index = np.argmax(f05s)\n",
    "    '''\n",
    "    while precision[optimal_index] == 1.0:\n",
    "        f05s[optimal_index] = 0\n",
    "        optimal_index = np.argmax(f05s)\n",
    "    '''\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "\n",
    "    optimal_P_by_fscore, optimal_R_by_fscore, optimal_F1_by_fscore, optimal_F05_by_fscore, optimal_T_by_fscore = precision[optimal_index], recall[optimal_index], f1s[optimal_index], f05s[optimal_index], threshold[optimal_index]\n",
    "    optimal_ACC_by_fscore = accuracy_score(y, pred > optimal_T_by_fscore)\n",
    "\n",
    "    print('----- Result stats -----' + anomaly_type)\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by F1-score:')\n",
    "    print('P: ' + str(optimal_P_by_fscore))\n",
    "    print('F05: ' + str(optimal_F05_by_fscore))\n",
    "    print('AUC: ' + str(auc))\n",
    "\n",
    "     # find the best threshold by 0.95 Precision\n",
    "    \n",
    "    filter_precision = np.array(precision)\n",
    "    filter_precision[filter_precision < 0.80] = 10\n",
    "    f1s = [get_f1(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    f05s = [get_f05(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    optimal_index = np.argmin(filter_precision)\n",
    "    if precision[optimal_index] == 1.0:\n",
    "        filter_precision = np.array(precision)\n",
    "        filter_precision[filter_precision == 1.0] = 0\n",
    "        optimal_index = np.argmax(filter_precision)\n",
    "    \n",
    "    for ind in range(len(precision)):\n",
    "        if recall[ind] >= 0.30 and precision[ind] >= 0.80:\n",
    "            optimal_index = ind\n",
    "            break\n",
    "\n",
    "    optimal_P_by_acc, optimal_R_by_acc, optimal_F1_by_acc, optimal_T_by_acc = precision[optimal_index], recall[optimal_index], f1s[optimal_index], threshold[min(optimal_index, len(threshold) - 1)]\n",
    "    optimal_ACC_by_acc = accuracy_score(y, pred > optimal_T_by_acc)\n",
    "\n",
    "# init parameters\n",
    "hop = 2 # ICEWS14 2; ICEWS05 2; YAGO 10 GD 2\n",
    "span = 2000 # ICEWS14 1000; ICEWS05 2000; YAGO 50 GD 12000\n",
    "time_specific = False # ICEWS14 F; ICEWS05 F; YAGO F\n",
    "span_t = 2000 # ICEWS14 200; ICEWS05 2000; YAGO 50 GD 12000\n",
    "span_m = 2000 # ICEWS14 150; ICEWS05 2000; YAGO 50 GD 12000\n",
    "max_rule = 10000 # ICEWS14 10000; ICEWS05 10000; YAGO 10000 GD 10000\n",
    "step = 2 # ICEWS14 2; ICEWS05 2; YAGO 1 GD 2\n",
    "aux_score = True # ICEWS14 T; ICEWS05 T; YAGO F GD F\n",
    "aux_score_m = False # ICEWS14 F; ICEWS05 F; YAGO F GD F\n",
    "distribution_aware = False # ICEWS14 T; ICEWS05 F; YAGO F GD F\n",
    "and_or = 'and' # ICEWS14 or; ICEWS05 and; YAGO or GD and\n",
    "update_sample_size = 10 # ICEWS14 10; ICEWS05 10; YAGO 20 GD 5 \n",
    "update_span = 3000 # ICEWS14 200; ICEWS05 3000; YAGO 20 GD 12000\n",
    "pred_list_C = [] # for concept anomaly\n",
    "label_list_C = []\n",
    "\n",
    "pred_list_T = [] # for time anomaly\n",
    "label_list_T = []\n",
    "\n",
    "pred_list_M = [] # for missing anomaly\n",
    "label_list_M = []\n",
    "\n",
    "time_specific_pred_list_C = []\n",
    "time_specific_label_list_C = []\n",
    "time_specific_pred_list_T = []\n",
    "time_specific_label_list_T = []\n",
    "time_specific_pred_list_M = []\n",
    "time_specific_label_list_M = []\n",
    "\n",
    "all_proj_rules = []\n",
    "def update_helper_valid(m):\n",
    "    raw_score, project_rules = detector.score_edge_temporal((int(m[0]), int(m[1]), int(m[2]), int(m[3])), hop = hop, max_span = span_t, and_or = and_or, max_step = step, aux_score = aux_score, dsa = distribution_aware, max_rule = max_rule, file_type='valid')\n",
    "    detector.update(m, project_rules, update_sample_size, update_span)\n",
    "\n",
    "def update_helper_test(x_y):\n",
    "    m = x_y[0]\n",
    "    project_rules = x_y[1]\n",
    "    detector.update(m, project_rules, update_sample_size, update_span)\n",
    "\n",
    "def concept_detect_helper(fact_label_t):\n",
    "    m = fact_label_t[0]\n",
    "    label = fact_label_t[1]\n",
    "    t = fact_label_t[2]\n",
    "    raw_score = detector.score_edge((int(m[0]), int(m[1]), int(m[2]), int(t)), hop = hop, max_span = span, and_or = and_or, time_specific = time_specific)\n",
    "    pred = sigmoid(raw_score)\n",
    "\n",
    "    return [pred, label]\n",
    "\n",
    "def temporal_detect_helper(fact_label_t):\n",
    "    m = fact_label_t[0]\n",
    "    label = fact_label_t[1]\n",
    "    t = fact_label_t[2]\n",
    "    raw_score, project_rules = detector.score_edge_temporal((int(m[0]), int(m[1]), int(m[2]), int(t)), hop = hop, max_span = span_t, and_or = and_or, max_step = step, aux_score = aux_score, dsa = distribution_aware, max_rule = max_rule, file_type='test')\n",
    "    pred = sigmoid(raw_score)\n",
    "\n",
    "    return [pred, label, m, project_rules]\n",
    "\n",
    "def missing_detect_helper(fact_label_t):\n",
    "    m = fact_label_t[0]\n",
    "    label = fact_label_t[1]\n",
    "    t = fact_label_t[2]\n",
    "    raw_score = detector.score_edge_missing((int(m[0]), int(m[1]), int(m[2]), int(t)), hop_c = hop, max_span_c = span, max_span_t = span_m, and_or = and_or, max_step = step, aux_score = aux_score_m, dsa = distribution_aware)\n",
    "    pred = sigmoid(-raw_score)\n",
    "\n",
    "    return [pred, label]\n",
    "\n",
    "p = mp.Pool(50)\n",
    "# update model in validate set\n",
    "for t in tqdm(valid_t_2_pos.keys()):\n",
    "    pos_samples = valid_t_2_pos[t]\n",
    "    #p.map(update_helper_valid, pos_samples)\n",
    "\n",
    "# detect anomalies in test set\n",
    "for t in tqdm(list(test_t_2_C_neg.keys())[:10]):\n",
    "    pos_samples = test_t_2_pos[t]\n",
    "    pos_missing = test_t_2_M_neg[1][t]\n",
    "\n",
    "    tmp_pred_C = []\n",
    "    tmp_label_C = []\n",
    "    tmp_pred_T = []\n",
    "    tmp_label_T = []\n",
    "    tmp_pred_M = []\n",
    "    tmp_label_M = []\n",
    "\n",
    "    concept_temporal_p = [[pos_samples[i], 0, t] for i in range(len(pos_samples))]\n",
    "    missing_p = [[pos_missing[i], 1, t] for i in range(len(pos_missing))]\n",
    "    concept_score_label_p = p.map(concept_detect_helper, concept_temporal_p)\n",
    "    temporal_score_label_proj_p = p.map(temporal_detect_helper, concept_temporal_p)\n",
    "    missing_score_label_p = p.map(missing_detect_helper, missing_p)\n",
    "    for i in range(len(concept_score_label_p)):\n",
    "        pred_list_C.append(concept_score_label_p[i][0])\n",
    "        label_list_C.append(concept_score_label_p[i][1])\n",
    "        tmp_pred_C.append(concept_score_label_p[i][0])\n",
    "        tmp_label_C.append(concept_score_label_p[i][1])\n",
    "    \n",
    "    for i in range(len(temporal_score_label_proj_p)):\n",
    "        pred_list_T.append(temporal_score_label_proj_p[i][0])\n",
    "        label_list_T.append(temporal_score_label_proj_p[i][1])\n",
    "        all_proj_rules.append([temporal_score_label_proj_p[i][2], temporal_score_label_proj_p[i][3]])\n",
    "        tmp_pred_T.append(temporal_score_label_proj_p[i][0])\n",
    "        tmp_label_T.append(temporal_score_label_proj_p[i][1])\n",
    "    \n",
    "    for i in range(len(missing_score_label_p)):\n",
    "        pred_list_M.append(missing_score_label_p[i][0])\n",
    "        label_list_M.append(missing_score_label_p[i][1])\n",
    "        tmp_pred_M.append(missing_score_label_p[i][0])\n",
    "        tmp_label_M.append(missing_score_label_p[i][1])\n",
    "    \n",
    "\n",
    "    concept_n = [[test_t_2_C_neg[t][i], 1, t] for i in range(len(test_t_2_C_neg[t]))]\n",
    "    temporal_n = [[test_t_2_T_neg[t][i], 1, t] for i in range(len(test_t_2_T_neg[t]))]\n",
    "    missing_n = [[test_t_2_M_neg[0][t][i], 0, t] for i in range(len(test_t_2_M_neg[0][t]))]\n",
    "    concept_score_label_n = p.map(concept_detect_helper, concept_n)\n",
    "    temporal_score_label_proj_n = p.map(temporal_detect_helper, temporal_n)\n",
    "    missing_score_label_n = p.map(missing_detect_helper, missing_n)\n",
    "    \n",
    "\n",
    "    for i in range(len(concept_score_label_n)):\n",
    "        pred_list_C.append(concept_score_label_n[i][0])\n",
    "        label_list_C.append(concept_score_label_n[i][1])\n",
    "        tmp_pred_C.append(concept_score_label_n[i][0])\n",
    "        tmp_label_C.append(concept_score_label_n[i][1])\n",
    "    \n",
    "    for i in range(len(temporal_score_label_proj_n)):\n",
    "        pred_list_T.append(temporal_score_label_proj_n[i][0])\n",
    "        label_list_T.append(temporal_score_label_proj_n[i][1])\n",
    "        tmp_pred_T.append(temporal_score_label_proj_n[i][0])\n",
    "        tmp_label_T.append(temporal_score_label_proj_n[i][1])\n",
    "    \n",
    "    for i in range(len(missing_score_label_n)):\n",
    "        pred_list_M.append(missing_score_label_n[i][0])\n",
    "        label_list_M.append(missing_score_label_n[i][1])\n",
    "        tmp_pred_M.append(missing_score_label_n[i][0])\n",
    "        tmp_label_M.append(missing_score_label_n[i][1])\n",
    "    \n",
    "    time_specific_pred_list_C.append(tmp_pred_C)\n",
    "    time_specific_label_list_C.append(tmp_label_C)\n",
    "    time_specific_pred_list_T.append(tmp_pred_T)\n",
    "    time_specific_label_list_T.append(tmp_label_T)\n",
    "    time_specific_pred_list_M.append(tmp_pred_M)\n",
    "    time_specific_label_list_M.append(tmp_label_M)\n",
    "    \n",
    "    # update model in test set\n",
    "    p.map(update_helper_test, all_proj_rules)\n",
    "    all_proj_rules = []\n",
    "\n",
    "get_metric(np.array(pred_list_C), np.array(label_list_C), 'concept') # concept\n",
    "get_metric(np.array(pred_list_T), np.array(label_list_T), 'time') # time\n",
    "get_metric(np.array(pred_list_M), np.array(label_list_M), 'missing') # missing\n",
    "detector.re_fresh()\n",
    "p.close()\n",
    "# 19min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_specific_pred_list_C)\n",
    "print(time_specific_label_list_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_specific_result_C = []\n",
    "time_specific_result_M = []\n",
    "time_specific_result_T = []\n",
    "\n",
    "def get_auc(pred, y):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return auc\n",
    "\n",
    "for i in range(len(time_specific_pred_list_C)):\n",
    "    time_specific_result_C.append(get_auc(time_specific_pred_list_C[i], time_specific_label_list_C[i]))\n",
    "    time_specific_result_T.append(get_auc(time_specific_pred_list_T[i], time_specific_label_list_T[i]))\n",
    "    time_specific_result_M.append(get_auc(time_specific_pred_list_M[i], time_specific_label_list_M[i]))\n",
    "\n",
    "#print(time_specific_result_M)\n",
    "pickle.dump([time_specific_result_C, time_specific_result_T, time_specific_result_M], open(root_path + dataset + \"auc_time.pickle\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# init parameters\n",
    "hop = 10 # ICEWS14 2; ICEWS05 2; YAGO 10 GD 2\n",
    "span = 50 # ICEWS14 1000; ICEWS05 2000; YAGO 50 GD 12000\n",
    "time_specific = False # ICEWS14 F; ICEWS05 F; YAGO F\n",
    "span_t = 50 # ICEWS14 200; ICEWS05 2000; YAGO 50 GD 12000\n",
    "span_m = 50 # ICEWS14 150; ICEWS05 2000; YAGO 50 GD 12000\n",
    "max_rule = 10000 # ICEWS14 10000; ICEWS05 10000; YAGO 10000 GD 10000\n",
    "step = 1 # ICEWS14 2; ICEWS05 2; YAGO 1 GD 2\n",
    "aux_score = False # ICEWS14 T; ICEWS05 T; YAGO F GD F\n",
    "aux_score_m = False # ICEWS14 F; ICEWS05 F; YAGO F GD F\n",
    "distribution_aware = False # ICEWS14 T; ICEWS05 F; YAGO F GD F\n",
    "and_or = 'and' # ICEWS14 or; ICEWS05 and; YAGO or GD and\n",
    "update_sample_size = 20 # ICEWS14 10; ICEWS05 10; YAGO 20 GD 5 \n",
    "update_span = 1 # ICEWS14 200; ICEWS05 3000; YAGO 20 GD 12000\n",
    "pred_list_C = [] # for concept anomaly\n",
    "label_list_C = []\n",
    "\n",
    "100%|██████████| 183/183 [02:14<00:00,  1.36it/s]\n",
    "100%|██████████| 5/5 [00:34<00:00,  6.89s/it]\n",
    "----- Result stats -----concept\n",
    "Number of test samples: 26029\n",
    "Number of anomaly samples: 6004\n",
    "100%|██████████| 183/183 [02:14<00:00,  1.36it/s]\n",
    "100%|██████████| 5/5 [00:33<00:00,  6.61s/it]\n",
    "----- Result stats -----concept\n",
    "Number of test samples: 26029\n",
    "Number of anomaly samples: 6004\n",
    "-----------------------\n",
    "Best result by F1-score:\n",
    "P: 0.4029403567447046\n",
    "F05: 0.4559862486595597\n",
    "AUC: 0.7685433597742994\n",
    "----- Result stats -----time\n",
    "Number of test samples: 26029\n",
    "Number of anomaly samples: 6004\n",
    "-----------------------\n",
    "Best result by F1-score:\n",
    "P: 0.24585397813357357\n",
    "F05: 0.28952241339402823\n",
    "AUC: 0.5401498127340825\n",
    "----- Result stats -----missing\n",
    "Number of test samples: 16117\n",
    "Number of anomaly samples: 6004\n",
    "-----------------------\n",
    "Best result by F1-score:\n",
    "P: 0.437957157784744\n",
    "F05: 0.45770994867314624\n",
    "AUC: 0.5093390885525211\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "hop = 2 # ICEWS14 2; ICEWS05 2; YAGO 10\n",
    "span = 12000 # ICEWS14 1000; ICEWS05 2000; YAGO 50\n",
    "span_t = 12000 # ICEWS14 200; ICEWS05 2000; YAGO 50\n",
    "span_m = 12000 # ICEWS14 150; ICEWS05 2000; YAGO 50\n",
    "step = 2 # ICEWS14 2; ICEWS05 2; YAGO 1\n",
    "aux_score = False # ICEWS14 T; ICEWS05 T; YAGO F\n",
    "aux_score_m = False # ICEWS14 F; ICEWS05 F; YAGO F\n",
    "distribution_aware = False # ICEWS14 T; ICEWS05 F; YAGO F\n",
    "and_or = 'and' # ICEWS14 or; ICEWS05 and; YAGO or\n",
    "update_sample_size = 20 # ICEWS14 10; ICEWS05 10; YAGO 20\n",
    "update_span = 200 # ICEWS14 200; ICEWS05 3000; YAGO 20\n",
    "\n",
    "no update max_label = 10, 5, 20 都差不多\n",
    "only out 性能下降\n",
    "num_cover_rules += 1 性能下降\n",
    "num_cover_rules += len(self.temporal_model.model.graph.candidates[rule]['ca_to_size']) +1 性能不变\n",
    "only 100 rules 微升\n",
    "Best result by F1-score:\n",
    "\n",
    "P: 0.8792565539471544\n",
    "F05: 0.82147139596952\n",
    "AUC: 0.9001228704018721\n",
    "\n",
    "\n",
    "P: 0.9336388634280477\n",
    "F05: 0.7963397938832097\n",
    "AUC: 0.8798370611945016\n",
    "\n",
    "P: 0.9236583668419425\n",
    "F05: 0.8007743103274897\n",
    "AUC: 0.8835251899489124\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "and + 3000span\n",
    "Best result by F1-score:\n",
    "P: 0.8535224586288416\n",
    "R: 0.6596988744335623\n",
    "F: 0.7441975512223276\n",
    "F0.5: 0.806151977421314\n",
    "ACC: 0.8962918400427801\n",
    "Threshold: 0.7424656560607265\n",
    "\n",
    "# span 3000\n",
    "Best result by F1-score:\n",
    "P: 0.8956037840845854\n",
    "R: 0.5881450080397602\n",
    "F: 0.7100189703092602\n",
    "F0.5: 0.8108298738462777\n",
    "ACC: 0.8901422101903377\n",
    "Threshold: 0.7424656560607265\n",
    "----- Result stats -----\n",
    "Number of test samples: 59841\n",
    "Number of anomaly samples: 13682\n",
    "-----------------------\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.8960589483085855\n",
    "R: 0.5866101447156848\n",
    "F: 0.7090419188126684\n",
    "ACC: 0.8898915459300479\n",
    "Threshold: 0.8175744761936437\n",
    "\n",
    "# span 100\n",
    "Best result by F1-score:\n",
    "P: 0.7405571697145787\n",
    "R: 0.6333869317351264\n",
    "F: 0.6827923101166089\n",
    "F0.5: 0.716316746569681\n",
    "ACC: 0.8653431593723367\n",
    "Threshold: 0.5621765008857981\n",
    "----- Result stats -----\n",
    "Number of test samples: 59841\n",
    "Number of anomaly samples: 13682\n",
    "-----------------------\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.7414878027756228\n",
    "R: 0.6287092530331823\n",
    "F: 0.6804572242218091\n",
    "ACC: 0.8649420965558731\n",
    "Threshold: 0.7439624913247581\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''                 \n",
    "                    concept    (OK)                                    \n",
    "no update           Best result by F1-score:                        \n",
    "                    P: 0.7842592592592592\n",
    "                    R: 0.7707006369426752\n",
    "                    F: 0.7774208352455254\n",
    "                    F0.5: 0.78150950359845\n",
    "                    ACC: 0.898526491796426\n",
    "                    Threshold: 0.7685247834990175\n",
    "\n",
    "                    Best result by 0.95 Precision:\n",
    "                    P: 0.7842592592592592\n",
    "                    R: 0.7707006369426752\n",
    "                    F: 0.7774208352455254\n",
    "                    ACC: 0.898526491796426\n",
    "                    Threshold: 0.7685247834990175\n",
    "'''\n",
    "\n",
    "'''                 \n",
    "                    time     (OK)                        \n",
    "no update           Best result by F1-score:\n",
    "                    P: 0.5449199607971251\n",
    "                    R: 0.7588717015468608\n",
    "                    F: 0.6343411294922989\n",
    "                    F0.5: 0.5774823431657665\n",
    "                    ACC: 0.7989340578952868\n",
    "                    Threshold: 0.923173382831992\n",
    "                    \n",
    "                    Best result by 0.95 Precision:\n",
    "                    P: 0.875\n",
    "                    R: 0.0031847133757961785\n",
    "                    F: 0.006346328195829557\n",
    "                    ACC: 0.7710314557425019\n",
    "                    Threshold: 0.9512665461461832\n",
    "'''\n",
    "\n",
    "'''                 \n",
    "                    missing     (OK)\n",
    "no update           Best result by F1-score:\n",
    "                    P: 0.8570014844136566\n",
    "                    R: 0.7879890809827116\n",
    "                    F: 0.8210476416212373\n",
    "                    F0.5: 0.8422485897685277\n",
    "                    ACC: 0.7707006369426752\n",
    "                    Threshold: 0.9175179090752534\n",
    "                    \n",
    "                    Best result by 0.95 Precision:\n",
    "                    P: 0.9321486268174475\n",
    "                    R: 0.3937670609645132\n",
    "                    F: 0.5536542459619384\n",
    "                    ACC: 0.5764331210191083\n",
    "                    Threshold: 0.9513380924144209\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect concept anomaly\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, f1_score\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def get_f1(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2*(p*r)/(p+r)\n",
    "\n",
    "def get_metric(pred, y):\n",
    "    precision, recall, threshold = precision_recall_curve(y, pred)\n",
    "    # find the best threshold by F1 score\n",
    "\n",
    "    f1s = [get_f1(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    optimal_index = np.argmax(f1s)\n",
    "\n",
    "    optimal_P_by_fscore, optimal_R_by_fscore, optimal_F1_by_fscore, optimal_T_by_fscore = precision[optimal_index], recall[optimal_index], f1s[optimal_index], threshold[optimal_index]\n",
    "    optimal_ACC_by_fscore = accuracy_score(y, pred > optimal_T_by_fscore)\n",
    "\n",
    "    print('----- Result stats -----')\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by F1-score:')\n",
    "    print('P: ' + str(optimal_P_by_fscore))\n",
    "    print('R: ' + str(optimal_R_by_fscore))\n",
    "    print('F: ' + str(optimal_F1_by_fscore))\n",
    "    print('ACC: ' + str(optimal_ACC_by_fscore))\n",
    "    print('Threshold: ' + str(optimal_T_by_fscore))\n",
    "\n",
    "    # find the best threshold by 0.95 Precision\n",
    "    filter_precision = np.array(precision)\n",
    "    filter_precision[filter_precision < 0.95] = 10\n",
    "    optimal_index = np.argmin(filter_precision)\n",
    "    if precision[optimal_index] == 1.0:\n",
    "        filter_precision = np.array(precision)\n",
    "        filter_precision[filter_precision == 1.0] = 0\n",
    "        optimal_index = np.argmax(filter_precision)\n",
    "\n",
    "    optimal_P_by_acc, optimal_R_by_acc, optimal_F1_by_acc, optimal_T_by_acc = precision[optimal_index], recall[optimal_index], f1s[optimal_index], threshold[min(optimal_index, len(threshold) - 1)]\n",
    "    optimal_ACC_by_acc = accuracy_score(y, pred > optimal_T_by_acc)\n",
    "\n",
    "    print('----- Result stats -----')\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by 0.95 Precision:')\n",
    "    print('P: ' + str(optimal_P_by_acc))\n",
    "    print('R: ' + str(optimal_R_by_acc))\n",
    "    print('F: ' + str(optimal_F1_by_acc))\n",
    "    print('ACC: ' + str(optimal_ACC_by_acc))\n",
    "    print('Threshold: ' + str(optimal_T_by_acc))\n",
    "\n",
    "\n",
    "# test in valid set\n",
    "for t in tqdm(valid_t_2_pos.keys()):\n",
    "    pos_samples = valid_t_2_pos[t]\n",
    "    for m in pos_samples:\n",
    "        detector.update(m)\n",
    "\n",
    "# test in test set\n",
    "hop = 2\n",
    "span = 1000\n",
    "pred_list = []\n",
    "label_list = []\n",
    "for t in tqdm(test_t_2_pos.keys()):\n",
    "    pos_samples = test_t_2_pos[t]\n",
    "    for m in pos_samples:\n",
    "        raw_score = detector.score_edge(m, hop, span)\n",
    "        pred = sigmoid(raw_score)\n",
    "        label = 0\n",
    "        pred_list.append(pred)\n",
    "        label_list.append(label)\n",
    "\n",
    "    neg_samples = test_t_2_C_neg[t] if t in test_t_2_C_neg.keys() else []\n",
    "    for m in neg_samples:\n",
    "        raw_score = detector.score_edge((int(m[0]), int(m[1]), int(m[2]), int(t)), hop, span)\n",
    "        pred = sigmoid(raw_score)\n",
    "        label = 1\n",
    "        pred_list.append(pred)\n",
    "        label_list.append(label)\n",
    "    for m in pos_samples:\n",
    "        detector.update(m)\n",
    "get_metric(np.array(pred_list), np.array(label_list))\n",
    "detector.re_fresh()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Best result by F1-score:\n",
    "P: 0.7874596588289534\n",
    "R: 0.7770700636942676\n",
    "F: 0.7822303640943439\n",
    "ACC: 0.900616574354687\n",
    "Threshold: 0.5199893401555818\n",
    "----- Result stats -----\n",
    "Number of test samples: 9569\n",
    "Number of anomaly samples: 2198\n",
    "-----------------------\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.7901869158878505\n",
    "R: 0.7693357597816196\n",
    "F: 0.7796219455970493\n",
    "ACC: 0.8999895495872087\n",
    "Threshold: 0.7685247834990175\n",
    "\n",
    "\n",
    "\n",
    "# no update\n",
    "Best result by F1-score:\n",
    "P: 0.7825886688162137\n",
    "R: 0.772975432211101\n",
    "F: 0.7777523460746166\n",
    "ACC: 0.898526491796426\n",
    "Threshold: 0.7431680086124811\n",
    "----- Result stats -----\n",
    "Number of test samples: 9569\n",
    "Number of anomaly samples: 2198\n",
    "-----------------------\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.7846225104214914\n",
    "R: 0.7707006369426752\n",
    "F: 0.7775992655496902\n",
    "ACC: 0.898630995924339\n",
    "Threshold: 0.7685247834990175\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect time anomaly\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, f1_score\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def get_f1(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "             return 2*(p*r)/(p+r)\n",
    "            #return 1.25*(p*r)/(0.25*p+r)\n",
    "\n",
    "def get_f05(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.25*(p*r)/(0.25*p+r)\n",
    "\n",
    "def get_metric(pred, y):\n",
    "    precision, recall, threshold = precision_recall_curve(y, pred)\n",
    "    # find the best threshold by F1 score\n",
    "\n",
    "    f1s = [get_f1(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    f05s = [get_f05(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    optimal_index = np.argmax(f05s)\n",
    "\n",
    "    optimal_P_by_fscore, optimal_R_by_fscore, optimal_F1_by_fscore, optimal_F05_by_fscore, optimal_T_by_fscore = precision[optimal_index], recall[optimal_index], f1s[optimal_index], f05s[optimal_index], threshold[optimal_index]\n",
    "    optimal_ACC_by_fscore = accuracy_score(y, pred > optimal_T_by_fscore)\n",
    "\n",
    "    print('----- Result stats -----')\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by F1-score:')\n",
    "    print('P: ' + str(optimal_P_by_fscore))\n",
    "    print('R: ' + str(optimal_R_by_fscore))\n",
    "    print('F: ' + str(optimal_F1_by_fscore))\n",
    "    print('F0.5: ' + str(optimal_F05_by_fscore))\n",
    "    print('ACC: ' + str(optimal_ACC_by_fscore))\n",
    "    print('Threshold: ' + str(optimal_T_by_fscore))\n",
    "\n",
    "    # find the best threshold by 0.95 Precision\n",
    "    filter_precision = np.array(precision)\n",
    "    filter_precision[filter_precision < 0.95] = 10\n",
    "    optimal_index = np.argmin(filter_precision)\n",
    "    if precision[optimal_index] == 1.0:\n",
    "        filter_precision = np.array(precision)\n",
    "        filter_precision[filter_precision == 1.0] = 0\n",
    "        optimal_index = np.argmax(filter_precision)\n",
    "\n",
    "    optimal_P_by_acc, optimal_R_by_acc, optimal_F1_by_acc, optimal_F05_by_fscore, optimal_T_by_acc = precision[optimal_index], recall[optimal_index], f1s[optimal_index], f05s[optimal_index], threshold[min(optimal_index, len(threshold) - 1)]\n",
    "    optimal_ACC_by_acc = accuracy_score(y, pred > optimal_T_by_acc)\n",
    "\n",
    "    print('----- Result stats -----')\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by 0.95 Precision:')\n",
    "    print('P: ' + str(optimal_P_by_acc))\n",
    "    print('R: ' + str(optimal_R_by_acc))\n",
    "    print('F: ' + str(optimal_F1_by_acc))\n",
    "    print('F0.5: ' + str(optimal_F05_by_fscore))\n",
    "    print('ACC: ' + str(optimal_ACC_by_acc))\n",
    "    print('Threshold: ' + str(optimal_T_by_acc))\n",
    "\n",
    "\n",
    "# test in valid set\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "true_scores = []\n",
    "false_scores = []\n",
    "for t in tqdm(valid_t_2_pos.keys()):\n",
    "    pos_samples = valid_t_2_pos[t]\n",
    "    for m in pos_samples:\n",
    "        detector.update(m)\n",
    "\n",
    "\n",
    "# test in test set\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "raw_score_list_p = []\n",
    "raw_score_list_n = []\n",
    "for t in tqdm(test_t_2_pos.keys()):\n",
    "    pos_samples = test_t_2_pos[t]\n",
    "    for m in pos_samples:\n",
    "        raw_score = detector.score_edge_temporal(m)\n",
    "        raw_score_list_p.append(raw_score)\n",
    "        pred = sigmoid(raw_score)\n",
    "        label = 0\n",
    "        pred_list.append(pred)\n",
    "        label_list.append(label)\n",
    "\n",
    "    neg_samples = test_t_2_T_neg[t] if t in test_t_2_T_neg.keys() else []\n",
    "    for m in neg_samples:\n",
    "        raw_score = detector.score_edge_temporal((int(m[0]), int(m[1]), int(m[2]), int(t)))\n",
    "        raw_score_list_n.append(raw_score)\n",
    "        pred = sigmoid(raw_score)\n",
    "        label = 1\n",
    "        pred_list.append(pred)\n",
    "        label_list.append(label)\n",
    "    for m in pos_samples:\n",
    "        detector.update(m)\n",
    "get_metric(np.array(pred_list), np.array(label_list))\n",
    "detector.re_fresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best result by F1-score:\n",
    "P: 0.6872586872586872\n",
    "R: 0.7288444040036397\n",
    "F: 0.7074409361890042\n",
    "F0.5: 0.6951918069779552\n",
    "ACC: 0.8612185181314662\n",
    "Threshold: 0.9241418199787566\n",
    "\n",
    "# no update\n",
    "Best result by F1-score:\n",
    "P: 0.5421412300683371\n",
    "R: 0.7579617834394905\n",
    "F: 0.6321381142098274\n",
    "F0.5: 0.5748792270531401\n",
    "ACC: 0.7972619918486781\n",
    "Threshold: 0.9214404114882956\n",
    "\n",
    "\n",
    "#pair单独排序；时间衰减\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.3124006359300477\n",
    "R: 0.7151956323930846\n",
    "F: 0.4348547717842323\n",
    "F0.5: 0.3520558989518947\n",
    "ACC: 0.5728916292193542\n",
    "Threshold: 0.5007204605964806\n",
    "\n",
    "#pair+triangle混合排序；允许内部二阶递归；1/计数;triange生成500_10；有时间间隔限制\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.31661600810536983\n",
    "R: 0.8530482256596906\n",
    "F: 0.46182266009852224\n",
    "F0.5: 0.36216487676736464\n",
    "ACC: 0.5432124568920472\n",
    "Threshold: 0.734699799197555\n",
    "\n",
    "#pair+triangle单独排序但混和选择会导致二阶规则几乎不被选入模型\n",
    "#pair+triangle单独排序且分别选择；只允许内部二阶递归时；性能下降\n",
    "#pair+triangle单独排序且分别选择；允许内部，外部二阶递归时；性能下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect missing anomaly\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, f1_score\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def get_f1(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "             return 2*(p*r)/(p+r)\n",
    "\n",
    "def get_f05(p, r):\n",
    "        if (p+r) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.25*(p*r)/(0.25*p+r)\n",
    "\n",
    "def get_metric(pred, y):\n",
    "    precision, recall, threshold = precision_recall_curve(y, pred)\n",
    "    # find the best threshold by F1 score\n",
    "\n",
    "    f1s = [get_f1(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    f05s = [get_f05(precision[i], recall[i]) for i in range(len(precision))]\n",
    "    optimal_index = np.argmax(f05s)\n",
    "\n",
    "    optimal_P_by_fscore, optimal_R_by_fscore, optimal_F1_by_fscore, optimal_F05_by_fscore, optimal_T_by_fscore = precision[optimal_index], recall[optimal_index], f1s[optimal_index], f05s[optimal_index], threshold[optimal_index]\n",
    "    optimal_ACC_by_fscore = accuracy_score(y, pred > optimal_T_by_fscore)\n",
    "\n",
    "    print('----- Result stats -----')\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by F1-score:')\n",
    "    print('P: ' + str(optimal_P_by_fscore))\n",
    "    print('R: ' + str(optimal_R_by_fscore))\n",
    "    print('F: ' + str(optimal_F1_by_fscore))\n",
    "    print('F0.5: ' + str(optimal_F05_by_fscore))\n",
    "    print('ACC: ' + str(optimal_ACC_by_fscore))\n",
    "    print('Threshold: ' + str(optimal_T_by_fscore))\n",
    "\n",
    "    # find the best threshold by 0.95 Precision\n",
    "    filter_precision = np.array(precision)\n",
    "    filter_precision[filter_precision < 0.95] = 10\n",
    "    optimal_index = np.argmin(filter_precision)\n",
    "    if precision[optimal_index] == 1.0:\n",
    "        filter_precision = np.array(precision)\n",
    "        filter_precision[filter_precision == 1.0] = 0\n",
    "        optimal_index = np.argmax(filter_precision)\n",
    "\n",
    "    optimal_P_by_acc, optimal_R_by_acc, optimal_F1_by_acc, optimal_F05_by_fscore, optimal_T_by_acc = precision[optimal_index], recall[optimal_index], f1s[optimal_index], f05s[optimal_index], threshold[min(optimal_index, len(threshold) - 1)]\n",
    "    optimal_ACC_by_acc = accuracy_score(y, pred > optimal_T_by_acc)\n",
    "\n",
    "    print('----- Result stats -----')\n",
    "    print('Number of test samples: ' + str(len(y)))\n",
    "    print('Number of anomaly samples: ' + str(sum(y)))\n",
    "    print('-----------------------')\n",
    "    print('Best result by 0.95 Precision:')\n",
    "    print('P: ' + str(optimal_P_by_acc))\n",
    "    print('R: ' + str(optimal_R_by_acc))\n",
    "    print('F: ' + str(optimal_F1_by_acc))\n",
    "    print('F0.5: ' + str(optimal_F05_by_fscore))\n",
    "    print('ACC: ' + str(optimal_ACC_by_acc))\n",
    "    print('Threshold: ' + str(optimal_T_by_acc))\n",
    "\n",
    "\n",
    "# test in valid set\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "true_scores = []\n",
    "false_scores = []\n",
    "for t in tqdm(valid_t_2_pos.keys()):\n",
    "    pos_samples = valid_t_2_pos[t]\n",
    "    for m in pos_samples:\n",
    "        detector.update(m)\n",
    "         \n",
    "\n",
    "# test in test set\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "raw_score_list_p = []\n",
    "raw_score_list_n = []\n",
    "missing_num = 0\n",
    "error_num = 0 \n",
    "for t in tqdm(test_t_2_pos.keys()):\n",
    "    pos_samples = test_t_2_pos[t]\n",
    "    pos_missing = test_t_2_M_neg[1][t]\n",
    "    for m in pos_missing:\n",
    "        missing_num+=1\n",
    "        raw_score = detector.score_edge_missing((int(m[0]), int(m[1]), int(m[2]), int(t)))\n",
    "        raw_score_list_p.append(raw_score)\n",
    "        pred = sigmoid(raw_score)\n",
    "        label = 0\n",
    "        pred_list.append(pred)\n",
    "        label_list.append(label)\n",
    "\n",
    "    neg_samples = test_t_2_M_neg[0][t]# if t in test_t_2_M_neg[0].keys() else []\n",
    "    for m in neg_samples:\n",
    "        error_num+=1\n",
    "        raw_score = detector.score_edge_missing((int(m[0]), int(m[1]), int(m[2]), int(t)))\n",
    "        raw_score_list_n.append(raw_score)\n",
    "        pred = sigmoid(raw_score)\n",
    "        label = 1\n",
    "        pred_list.append(pred)\n",
    "        label_list.append(label)\n",
    "    for m in pos_samples:\n",
    "        detector.update(m)\n",
    "get_metric(np.array(pred_list), np.array(label_list))\n",
    "detector.re_fresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best result by 0.95 Precision:\n",
    "P: 0.9362050163576882\n",
    "R: 0.390582347588717\n",
    "F: 0.5512038523274478\n",
    "F0.5: 0.7317592908285032\n",
    "ACC: 0.3333333333333333\n",
    "Threshold: 0.9525741268224334\n",
    "\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.9331536388140161\n",
    "R: 0.3937670609645132\n",
    "F: 0.5538313869780835\n",
    "F0.5: 0.7324813811780635\n",
    "ACC: 0.5767364270548984\n",
    "Threshold: 0.9514022157375411\n",
    "\n",
    "# no update\n",
    "Best result by 0.95 Precision:\n",
    "P: 0.932972972972973\n",
    "R: 0.39262966333030025\n",
    "F: 0.5526737111751522\n",
    "F0.5: 0.731603933536792\n",
    "ACC: 0.5759781619654231\n",
    "Threshold: 0.9308615796566533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(temporal_model.rule_to_time.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temporal_model.rule_to_time[(((43, 0, 45, 'in'), (45, 15, 44, 'out')), (44, 0, 43, 'out'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.e_2_t_list[1000].keys())\n",
    "print(graph.e_2_t_list[1000][296])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################测试部分#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "triple_sample_size = 100\n",
    "rule_sample_size = 5\n",
    "max_time = max(list(graph.t_2_triple.keys()))\n",
    "\n",
    "triangle_list = dict()\n",
    "for time in tqdm(sorted(list(graph.t_2_triple.keys()))):\n",
    "    triple_list = graph.t_2_triple[time]\n",
    "    for triple in list(triple_list)[:100]:\n",
    "        sub = triple[0]\n",
    "        pred = triple[1]\n",
    "        obj = triple[2]\n",
    "        next_time_list = set([time])\n",
    "        if time in graph.e_2_t_list[sub].keys():\n",
    "            next_time_list.add(graph.e_2_t_list[sub][time])\n",
    "        if time in graph.e_2_t_list[obj].keys():\n",
    "            next_time_list.add(graph.e_2_t_list[obj][time])\n",
    "\n",
    "        for in_time in next_time_list:\n",
    "            triple_list_2rd = set()\n",
    "            delete_set = set()\n",
    "            if sub in graph.t_e_2_triple[in_time].keys():\n",
    "                triple_list_2rd = triple_list_2rd | graph.t_e_2_triple[in_time][sub] \n",
    "                delete_set = graph.t_e_2_triple[in_time][sub]\n",
    "            if obj in graph.t_e_2_triple[in_time].keys():\n",
    "                triple_list_2rd = triple_list_2rd | graph.t_e_2_triple[in_time][obj]\n",
    "                delete_set = delete_set & graph.t_e_2_triple[in_time][obj]\n",
    "            \n",
    "            triple_list_2rd = triple_list_2rd - delete_set\n",
    "\n",
    "            for triple_2rd in list(triple_list_2rd)[:100]:\n",
    "                sub_2 = triple_2rd[0]\n",
    "                pred_2 = triple_2rd[1]\n",
    "                obj_2 = triple_2rd[2]\n",
    "                \n",
    "                co_e = list(set([sub, obj]) & set([sub_2, obj_2]))[0]\n",
    "                candidate_e_1 = sub if obj == co_e else obj\n",
    "                candidate_e_2 = sub_2 if obj_2 == co_e else obj_2\n",
    "                \n",
    "                next_time_list = set([in_time])\n",
    "                if in_time in graph.e_2_t_list[candidate_e_1].keys():\n",
    "                    next_time_list.add(graph.e_2_t_list[candidate_e_1][in_time])\n",
    "                if in_time in graph.e_2_t_list[candidate_e_2].keys():\n",
    "                    next_time_list.add(graph.e_2_t_list[candidate_e_2][in_time])\n",
    "\n",
    "                for close_time in next_time_list:\n",
    "                    triple_list_3rd = set()\n",
    "                    if (candidate_e_1, candidate_e_2) in graph.t_pair_2_triple[close_time].keys():\n",
    "                        triple_list_3rd = triple_list_3rd | graph.t_pair_2_triple[close_time][(candidate_e_1, candidate_e_2)]\n",
    "                    if (candidate_e_2, candidate_e_1) in graph.t_pair_2_triple[close_time].keys():\n",
    "                        triple_list_3rd = triple_list_3rd | graph.t_pair_2_triple[close_time][(candidate_e_2, candidate_e_1)]\n",
    "                    \n",
    "                    for triple_3rd in list(triple_list_3rd)[:100]:\n",
    "                        candidate_1_rule = sorted(graph.triple_to_rule[triple], reverse=True, key=lambda g: len(graph.candidates[g]['triples']))[: rule_sample_size]\n",
    "                        candidate_2_rule = sorted(graph.triple_to_rule[triple_2rd], reverse=True, key=lambda g: len(graph.candidates[g]['triples']))[: rule_sample_size]\n",
    "                        candidate_3_rule = graph.triple_to_rule[triple_3rd]\n",
    "\n",
    "                        \n",
    "                        for rule_1 in candidate_1_rule:\n",
    "                            for rule_2 in candidate_2_rule:\n",
    "                                co_e_list = list(set([rule_1[0], rule_1[2]]) & set([rule_2[0], rule_2[2]]))\n",
    "                                if len(co_e_list) != 1:\n",
    "                                    continue\n",
    "                                co_e = co_e_list[0]\n",
    "                                rule_3_e_1 = rule_1[0] if rule_1[2] == co_e else rule_1[2]\n",
    "                                rule_3_e_2 = rule_2[0] if rule_2[2] == co_e else rule_2[2]\n",
    "                                combined_rules = [(rule_3_e_1, triple_3rd[1], rule_3_e_2, 'out'), (rule_3_e_2, triple_3rd[1], rule_3_e_1, 'out'), (rule_3_e_1, triple_3rd[1], rule_3_e_2, 'in'), (rule_3_e_2, triple_3rd[1], rule_3_e_1, 'in')]\n",
    "                                for rule_3 in combined_rules:\n",
    "                                    if rule_3 in candidate_3_rule:\n",
    "                                        if (rule_1, rule_2, rule_3) not in triangle_list.keys():\n",
    "                                            triangle_list[(rule_1, rule_2, rule_3)] = set()\n",
    "                                        triangle_list[(rule_1, rule_2, rule_3)].add((triple_3rd[0], triple_3rd[1], triple_3rd[2]))\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "triple_sample_size = 1000\n",
    "rule_sample_size = 5\n",
    "max_time = max(list(graph.t_2_triple.keys()))\n",
    "covered_set = set()\n",
    "\n",
    "triangle_list = dict()\n",
    "for time in tqdm(sorted(list(graph.t_2_triple.keys()), reverse=True)):\n",
    "    target_triple_list = list(graph.t_2_triple[time])\n",
    "    for target_triple in target_triple_list[:triple_sample_size]:\n",
    "        if target_triple in covered_set:\n",
    "            continue\n",
    "        sub = target_triple[0]\n",
    "        pred = target_triple[1]\n",
    "        obj = target_triple[2]\n",
    "        pre_time_list = set([time])\n",
    "        if time in graph.e_2_t_list[sub].keys():\n",
    "            pre_time_list.add(graph.e_2_t_list[sub][time])\n",
    "        if time in graph.e_2_t_list[obj].keys():\n",
    "            pre_time_list.add(graph.e_2_t_list[obj][time])\n",
    "\n",
    "        for in_time in pre_time_list:\n",
    "            triple_list_2rd = set()\n",
    "            delete_set = set()\n",
    "            if sub in graph.t_e_2_triple[in_time].keys():\n",
    "                triple_list_2rd = triple_list_2rd | graph.t_e_2_triple[in_time][sub] \n",
    "                delete_set = graph.t_e_2_triple[in_time][sub]\n",
    "            if obj in graph.t_e_2_triple[in_time].keys():\n",
    "                triple_list_2rd = triple_list_2rd | graph.t_e_2_triple[in_time][obj]\n",
    "                delete_set = delete_set & graph.t_e_2_triple[in_time][obj]\n",
    "            \n",
    "            triple_list_2rd = triple_list_2rd - delete_set\n",
    "            \n",
    "            for triple_2rd in list(triple_list_2rd)[:triple_sample_size]:\n",
    "                sub_2 = triple_2rd[0]\n",
    "                pred_2 = triple_2rd[1]\n",
    "                obj_2 = triple_2rd[2]\n",
    "\n",
    "                co_e = list(set([sub, obj]) & set([sub_2, obj_2]))[0]\n",
    "                candidate_e_1 = sub if obj == co_e else obj\n",
    "                candidate_e_2 = sub_2 if obj_2 == co_e else obj_2\n",
    "\n",
    "                pre_time_list = set([in_time])\n",
    "                if in_time in graph.e_2_t_list[candidate_e_1].keys():\n",
    "                    pre_time_list.add(graph.e_2_t_list[candidate_e_1][in_time])\n",
    "                if in_time in graph.e_2_t_list[candidate_e_2].keys():\n",
    "                    pre_time_list.add(graph.e_2_t_list[candidate_e_2][in_time])\n",
    "\n",
    "                for close_time in pre_time_list:\n",
    "                    triple_list_3rd = set()\n",
    "                    if (candidate_e_1, candidate_e_2) in graph.t_pair_2_triple[close_time].keys():\n",
    "                        triple_list_3rd = triple_list_3rd | graph.t_pair_2_triple[close_time][(candidate_e_1, candidate_e_2)]\n",
    "                    if (candidate_e_2, candidate_e_1) in graph.t_pair_2_triple[close_time].keys():\n",
    "                        triple_list_3rd = triple_list_3rd | graph.t_pair_2_triple[close_time][(candidate_e_2, candidate_e_1)]\n",
    "                    \n",
    "                    for triple_3rd in list(triple_list_3rd)[:100]:\n",
    "                        candidate_1_rule = sorted(graph.triple_to_rule[target_triple], reverse=True, key=lambda g: len(graph.candidates[g]['triples']))[: rule_sample_size]\n",
    "                        candidate_2_rule = sorted(graph.triple_to_rule[triple_2rd], reverse=True, key=lambda g: len(graph.candidates[g]['triples']))[: rule_sample_size]\n",
    "                        candidate_3_rule = graph.triple_to_rule[triple_3rd]\n",
    "\n",
    "                        \n",
    "                        for rule_1 in candidate_1_rule:\n",
    "                            for rule_2 in candidate_2_rule:\n",
    "                                co_e_list = list(set([rule_1[0], rule_1[2]]) & set([rule_2[0], rule_2[2]]))\n",
    "                                if len(co_e_list) != 1:\n",
    "                                    continue\n",
    "                                co_e = co_e_list[0]\n",
    "                                rule_3_e_1 = rule_1[0] if rule_1[2] == co_e else rule_1[2]\n",
    "                                rule_3_e_2 = rule_2[0] if rule_2[2] == co_e else rule_2[2]\n",
    "                                combined_rules = [(rule_3_e_1, triple_3rd[1], rule_3_e_2, 'out'), (rule_3_e_2, triple_3rd[1], rule_3_e_1, 'out'), (rule_3_e_1, triple_3rd[1], rule_3_e_2, 'in'), (rule_3_e_2, triple_3rd[1], rule_3_e_1, 'in')]\n",
    "                                for rule_3 in combined_rules:\n",
    "                                    if rule_3 in candidate_3_rule:\n",
    "                                        if (rule_1, rule_2, rule_3) not in triangle_list.keys():\n",
    "                                            triangle_list[(rule_1, rule_2, rule_3)] = set()\n",
    "                                        covered_set.add((sub, pred, obj, time))\n",
    "                                        triangle_list[(rule_1, rule_2, rule_3)].add((sub, pred, obj, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "triple_sample_size = 1000\n",
    "rule_sample_size = 5\n",
    "max_time = max(list(graph.t_2_triple.keys()))\n",
    "covered_set = set()\n",
    "\n",
    "def get_rule_triangle(target_triple, sub_triple, obj_triple, triangle_list, covered_set):\n",
    "    tmp_set = set()\n",
    "    tar_sub, tar_pred, tar_obj, tar_dir = target_triple[0], target_triple[1], target_triple[2], target_triple[3]\n",
    "    co_e_list = list(set([sub_triple[0], sub_triple[2]]) & set([obj_triple[0], obj_triple[2]]))\n",
    "    co_e = co_e_list[0]\n",
    "    if sub_triple[0] == co_e:\n",
    "        sub_triple_type = 'co_sub'\n",
    "    else:\n",
    "        sub_triple_type = 'sub_co'\n",
    "    sub_pred, sub_dir = sub_triple[1], sub_triple[3]\n",
    "\n",
    "    if obj_triple[0] == co_e:\n",
    "        obj_triple_type = 'co_obj'\n",
    "    else:\n",
    "        obj_triple_type = 'obj_co'\n",
    "    obj_pred, obj_dir = obj_triple[1], obj_triple[3]\n",
    "\n",
    "    for type_1 in graph.node_to_labels[tar_sub][:rule_sample_size]:\n",
    "        for type_2 in graph.node_to_labels[tar_obj][:rule_sample_size]:\n",
    "            target_rules = (type_1, tar_pred, type_2, tar_dir)\n",
    "            for type_3 in graph.node_to_labels[co_e][:rule_sample_size]:\n",
    "                \n",
    "                if sub_triple_type == 'co_sub':\n",
    "                    sub_rules = (type_3, sub_pred, type_1, sub_dir)\n",
    "                else:\n",
    "                    sub_rules = (type_1, sub_pred, type_3, sub_dir)\n",
    "\n",
    "                if obj_triple_type == 'co_obj':\n",
    "                    obj_rules = (type_3, obj_pred, type_1, obj_dir)\n",
    "                else:\n",
    "                    obj_rules = (type_1, obj_pred, type_3, obj_dir)\n",
    "\n",
    "                rule_triangle = (sub_rules, obj_rules, target_rules)\n",
    "                if rule_triangle not in triangle_list.keys():\n",
    "                    triangle_list[rule_triangle] = set()\n",
    "                covered_set.add(target_triple)\n",
    "                triangle_list[rule_triangle].add(target_triple)\n",
    "\n",
    "triangle_list = dict()\n",
    "for time in tqdm(sorted(list(graph.t_2_triple.keys()), reverse=True)):\n",
    "    target_triple_list = list(graph.t_2_triple[time])\n",
    "    for target_triple in target_triple_list:\n",
    "        if target_triple in covered_set:\n",
    "            continue\n",
    "        sub = target_triple[0]\n",
    "        pred = target_triple[1]\n",
    "        obj = target_triple[2]\n",
    "        pre_time_list_sub = set([time])\n",
    "        pre_time_list_obj = set([time])\n",
    "        if time in graph.e_2_t_list[sub].keys():\n",
    "            pre_time_list_sub = list(pre_time_list_sub | set(graph.e_2_t_list[sub][time]))[:10]\n",
    "        if time in graph.e_2_t_list[obj].keys():\n",
    "            pre_time_list_obj = list(pre_time_list_obj | set(graph.e_2_t_list[obj][time]))[:10]\n",
    "\n",
    "        triple_list_sub = set()\n",
    "        triple_list_obj = set()\n",
    "        delete_set = set()\n",
    "        for in_time in pre_time_list_sub:\n",
    "            triple_list_sub = triple_list_sub | graph.t_e_2_triple[in_time][sub]\n",
    "            delete_set = graph.t_e_2_triple[in_time][sub]\n",
    "        for in_time in pre_time_list_obj:\n",
    "            triple_list_obj = triple_list_obj | graph.t_e_2_triple[in_time][obj]\n",
    "            delete_set = delete_set & graph.t_e_2_triple[in_time][obj]\n",
    "        \n",
    "        triple_list_sub = list(triple_list_sub - delete_set)\n",
    "        triple_list_obj = list(triple_list_obj - delete_set)\n",
    "        \n",
    "        for sub_triple in triple_list_sub[:triple_sample_size]:\n",
    "            for obj_triple in triple_list_obj[:triple_sample_size]:\n",
    "                if len(set([sub_triple[0], sub_triple[2], target_triple[0], target_triple[2]])) != 3:\n",
    "                    continue\n",
    "                if len(set([obj_triple[0], obj_triple[2], target_triple[0], target_triple[2]])) != 3:\n",
    "                    continue\n",
    "                if len(set([sub_triple[0], sub_triple[2], obj_triple[0], obj_triple[2]])) != 3:\n",
    "                    continue\n",
    "                get_rule_triangle(target_triple, sub_triple, obj_triple, triangle_list, covered_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule sample -->9337468  100%|██████████| 304/304 [05:52<00:00,  1.95s/it]\n",
    "# rule+triple sample --> 3007838\n",
    "print(len(triangle_list))\n",
    "#print(triangle_list)\n",
    "print(len(covered_set), graph.fact_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(44, 16, 50, 'in') in graph.candidates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(50, 16, 44, 'in') in graph.candidates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "graph_name = 'GDELT'\n",
    "root_path = '/home/zhangjs/expriment/TKGist/data/'\n",
    "dataset = graph_name+'/'\n",
    "\n",
    "def read_file(input_file):\n",
    "    raw_data = []\n",
    "    for fact in input_file.readlines():\n",
    "        s, r, o, t = fact.strip().split('\t')[:4]\n",
    "        s = int(s)\n",
    "        r = int(r)\n",
    "        o = int(o)\n",
    "        t = int(t)\n",
    "        raw_data.append((s, r, o, t))\n",
    "    return raw_data\n",
    "\n",
    "valid_t_2_C_neg, test_t_2_C_neg = pickle.load(open(root_path + dataset + '/conceptual_errors.pickle', 'rb'))\n",
    "valid_t_2_T_neg, test_t_2_T_neg = pickle.load(open(root_path + dataset + '/time_errors.pickle', 'rb'))\n",
    "valid_t_2_M_neg, test_t_2_M_neg = pickle.load(open(root_path + dataset + '/missing_errors.pickle', 'rb'))\n",
    "\n",
    "num_anom_C = 0\n",
    "for time in test_t_2_C_neg.keys():\n",
    "    num_anom_C += len(test_t_2_C_neg[time])\n",
    "\n",
    "num_anom_T = 0\n",
    "for time in test_t_2_T_neg.keys():\n",
    "    num_anom_T += len(test_t_2_T_neg[time])\n",
    "\n",
    "num_anom_M = 0\n",
    "for time in test_t_2_M_neg[1].keys():\n",
    "    num_anom_M += len(test_t_2_M_neg[1][time])\n",
    "\n",
    "print([num_anom_C, num_anom_T, num_anom_M])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
